{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Statefarm Redux\n",
    "Here we follow the main statefarm notebook, on our reduxed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named utils",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4e017bdcfb40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/state/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#path = \"data/state/sample/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileLink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named utils"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "path = \"data/state/\"\n",
    "#path = \"data/state/sample/\"\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/kaggle_data/state-farm-redux\n",
      "/home/ubuntu/courses/deeplearning1/nbs/kaggle_data/state-farm-redux\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "%cd /home/ubuntu/courses/deeplearning1/nbs/kaggle_data/state-farm-redux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data = \"/home/ubuntu/courses/deeplearning1/nbs/kaggle_data/state-farm-redux/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16564 images belonging to 10 classes.\n",
      "Found 5786 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path_to_data +'train', batch_size=batch_size)\n",
    "val_batches = get_batches(path_to_data +'valid', batch_size=batch_size*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16564 images belonging to 10 classes.\n",
      "Found 5786 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16564 images belonging to 10 classes.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d3ede07f9143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# instead of batching we can also load up all data into an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_data\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msave_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_data\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'results/trn.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtrn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mutils.pyc\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(path, target_size)\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrayscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_ordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_ordering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/preprocessing/image.pyc\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, target_size)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Ensure 3 channel even when loaded image is grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/PIL/ImageFile.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                         \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# instead of batching we can also load up all data into an array\n",
    "trn = get_data(path_to_data +'train')\n",
    "save_array(path_to_data +'results/trn.dat', trn)\n",
    "del trn\n",
    "\n",
    "val = get_data(path_to_data +'valid')\n",
    "save_array(path_to_data +'results/val.dat', val)\n",
    "del val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7ce90ecbec20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_data\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'results/val.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_data\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'results/trn.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mutils.pyc\u001b[0m in \u001b[0;36mload_array\u001b[0;34m(fname)\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray.__getitem__ (bcolz/carray_ext.c:25668)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val = load_array(path_to_data +'results/val.dat')\n",
    "trn = load_array(path_to_data +'results/trn.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run experiments\n",
    "on the entire set now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv1(batches):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "            Convolution2D(32,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Convolution2D(64,3,3, activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Flatten(),\n",
    "            Dense(200, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, batches.nb_sample, nb_epoch=4, validation_data=val_batches, \n",
    "                     nb_val_samples=val_batches.nb_sample)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 7584/16564 [============>.................] - ETA: 195s - loss: 0.3976 - acc: 0.8982"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d117e1e33da9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-8567c756ea2c>\u001b[0m in \u001b[0;36mconv1\u001b[0;34m(batches)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     model.fit_generator(batches, batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n\u001b[0;32m---> 18\u001b[0;31m                      nb_val_samples=val_batches.nb_sample)\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     model.fit_generator(batches, batches.nb_sample, nb_epoch=4, validation_data=val_batches, \n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    872\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1441\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1442\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1444\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = conv1(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16564 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "batches = get_batches(path_to_data +'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "16564/16564 [==============================] - 413s - loss: 1.2668 - acc: 0.5934 - val_loss: 1.5601 - val_acc: 0.5149\n",
      "Epoch 2/2\n",
      " 8416/16564 [==============>...............] - ETA: 164s - loss: 0.7115 - acc: 0.7779"
     ]
    }
   ],
   "source": [
    "model = conv1(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.0001\n",
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=15, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three conv + maxpool and dropout\n",
    "The results from above might be good but unstable - plus we want to try more complex models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16564 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "batches = get_batches(path_to_data+'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(128,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=10e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "16564/16564 [==============================] - 533s - loss: 2.5443 - acc: 0.2706 - val_loss: 1.7020 - val_acc: 0.4941\n",
      "Epoch 2/2\n",
      "16564/16564 [==============================] - 508s - loss: 1.7891 - acc: 0.4348 - val_loss: 1.5494 - val_acc: 0.4943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd80588ac10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=2, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16564/16564 [==============================] - 509s - loss: 1.4124 - acc: 0.5376 - val_loss: 1.4612 - val_acc: 0.5316\n",
      "Epoch 2/10\n",
      "16564/16564 [==============================] - 508s - loss: 1.1118 - acc: 0.6287 - val_loss: 1.5438 - val_acc: 0.5648\n",
      "Epoch 3/10\n",
      "16564/16564 [==============================] - 508s - loss: 0.9552 - acc: 0.6809 - val_loss: 1.6172 - val_acc: 0.5461\n",
      "Epoch 4/10\n",
      " 2048/16564 [==>...........................] - ETA: 377s - loss: 0.7841 - acc: 0.7163"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-27df0c91f92d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches, \n\u001b[0;32m----> 2\u001b[0;31m                  nb_val_samples=val_batches.nb_sample)\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    872\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1441\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1442\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1444\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  288/16564 [..............................] - ETA: 447s - loss: 0.9030 - acc: 0.7188"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-27df0c91f92d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches, \n\u001b[0;32m----> 2\u001b[0;31m                  nb_val_samples=val_batches.nb_sample)\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    872\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1441\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1442\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1444\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(batches, batches.nb_sample, nb_epoch=10, validation_data=val_batches, \n",
    "                 nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using vgg16\n",
    "It's likely that we want to keep all the weights up to the end of convolutional layers, since the same filters might be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "model = vgg.model\n",
    "last_conv_idx = [i for i, l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16564 images belonging to 10 classes.\n",
      "Found 16564 images belonging to 10 classes.\n",
      "Found 5786 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# when precomputing features we need to set shuffle to false BECAUSE WE NEED FEATURES IN THE SAME ORDER FOR TRAIN, VAL AND TEST\n",
    "# BECAUSE THEY WILL BE PASSED TO ANOTHER MODEL!\n",
    "batches = get_batches(path_to_data + \"train/\", batch_size=batch_size, shuffle=False)\n",
    "(val_classes, trn_classes, val_labels, trn_labels, val_filenames, filenames, test_filenames) = get_classes(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n",
      "Found 5786 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = get_batches(path_to_data + \"test/\", batch_size=batch_size, shuffle=False)\n",
    "val_batches = get_batches(path_to_data + \"valid/\", batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f9e237b674c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconv_val_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, val_samples, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m    943\u001b[0m                                             \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                                             \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m                                             pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, val_samples, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1634\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1635\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1636\u001b[0m                 \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1272\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conv_feat = conv_model.predict_generator(batches, batches.nb_sample)\n",
    "conv_val_feat = conv_model.predict_generator(val_batches, val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_test_feat = conv_model.predict_generator(test_batches, test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "God Daaaamn!\n"
     ]
    }
   ],
   "source": [
    "print(\"God Daaaamn!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path_to_data+'results/conv_val_feat.dat', conv_val_feat)\n",
    "save_array(path_to_data+'results/conv_test_feat.dat', conv_test_feat)\n",
    "save_array(path_to_data+'results/conv_feat.dat', conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5786, 512, 14, 14)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_feat = load_array(path_to_data+'results/conv_feat.dat')\n",
    "conv_val_feat = load_array(path_to_data+'results/conv_val_feat.dat')\n",
    "conv_val_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_test_feat = load_array(path_to_data + \"results/conv_test_feat.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### batchnorm on pretrained conv layers\n",
    "We have effectively taken the vgg conv layers as they were and used them to precompute features from our train/test/val batches. We need to take those predictions and use them as input to make predictions about our 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape = conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation=\"softmax\"),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv_test_feat', 32002654352),\n",
       " ('conv_feat', 6648922256),\n",
       " ('conv_val_feat', 2322546832),\n",
       " ('trn_labels', 1325232),\n",
       " ('test_filenames', 651360),\n",
       " ('val_labels', 462992),\n",
       " ('filenames', 140592),\n",
       " ('trn_classes', 66352),\n",
       " ('val_filenames', 48472),\n",
       " ('val_classes', 23240),\n",
       " ('Activation', 904),\n",
       " ('Adam', 904),\n",
       " ('AtrousConv1D', 904),\n",
       " ('AtrousConv2D', 904),\n",
       " ('AtrousConvolution1D', 904),\n",
       " ('AtrousConvolution2D', 904),\n",
       " ('AveragePooling1D', 904),\n",
       " ('AveragePooling2D', 904),\n",
       " ('AveragePooling3D', 904),\n",
       " ('BatchNormalization', 904),\n",
       " ('Bidirectional', 904),\n",
       " ('Conv1D', 904),\n",
       " ('Conv2D', 904),\n",
       " ('Conv3D', 904),\n",
       " ('Convolution1D', 904),\n",
       " ('Convolution2D', 904),\n",
       " ('Convolution3D', 904),\n",
       " ('Cropping1D', 904),\n",
       " ('Cropping2D', 904),\n",
       " ('Cropping3D', 904),\n",
       " ('Deconv2D', 904),\n",
       " ('Deconvolution2D', 904),\n",
       " ('Dense', 904),\n",
       " ('Dropout', 904),\n",
       " ('Embedding', 904),\n",
       " ('FileLink', 904),\n",
       " ('Flatten', 904),\n",
       " ('GRU', 904),\n",
       " ('GlobalAveragePooling2D', 904),\n",
       " ('InputSpec', 904),\n",
       " ('LSTM', 904),\n",
       " ('Lambda', 904),\n",
       " ('Layer', 904),\n",
       " ('MaxPooling1D', 904),\n",
       " ('MaxPooling2D', 904),\n",
       " ('MaxPooling3D', 904),\n",
       " ('MixIterator', 904),\n",
       " ('Model', 904),\n",
       " ('OneHotEncoder', 904),\n",
       " ('OrderedDict', 904),\n",
       " ('RMSprop', 904),\n",
       " ('Reshape', 904),\n",
       " ('SGD', 904),\n",
       " ('SeparableConv2D', 904),\n",
       " ('SeparableConvolution2D', 904),\n",
       " ('Sequential', 904),\n",
       " ('SimpleRNN', 904),\n",
       " ('TSNE', 904),\n",
       " ('TimeDistributed', 904),\n",
       " ('Tokenizer', 904),\n",
       " ('UpSampling1D', 904),\n",
       " ('UpSampling2D', 904),\n",
       " ('UpSampling3D', 904),\n",
       " ('ZeroPadding1D', 904),\n",
       " ('ZeroPadding2D', 904),\n",
       " ('ZeroPadding3D', 904),\n",
       " ('attrgetter', 872),\n",
       " ('chain', 872),\n",
       " ('itemgetter', 872),\n",
       " ('methodcaller', 872),\n",
       " ('conv_layers', 320),\n",
       " ('vgg_mean', 128),\n",
       " ('Input', 120),\n",
       " ('activity_l1', 120),\n",
       " ('activity_l2', 120),\n",
       " ('adjust_dropout', 120),\n",
       " ('categorical_accuracy', 120),\n",
       " ('categorical_crossentropy', 120),\n",
       " ('ceil', 120),\n",
       " ('confusion_matrix', 120),\n",
       " ('conv1', 120),\n",
       " ('conv2d', 120),\n",
       " ('conv_input_length', 120),\n",
       " ('conv_output_length', 120),\n",
       " ('copy_layer', 120),\n",
       " ('copy_layers', 120),\n",
       " ('copy_model', 120),\n",
       " ('copy_weights', 120),\n",
       " ('do_clip', 120),\n",
       " ('floor', 120),\n",
       " ('get_batches', 120),\n",
       " ('get_bn_layers', 120),\n",
       " ('get_classes', 120),\n",
       " ('get_data', 120),\n",
       " ('get_file', 120),\n",
       " ('gray', 120),\n",
       " ('imread', 120),\n",
       " ('insert_layer', 120),\n",
       " ('l1', 120),\n",
       " ('l2', 120),\n",
       " ('layer_from_config', 120),\n",
       " ('load_array', 120),\n",
       " ('merge', 120),\n",
       " ('mk_size', 120),\n",
       " ('mk_square', 120),\n",
       " ('onehot', 120),\n",
       " ('plot', 120),\n",
       " ('plot_confusion_matrix', 120),\n",
       " ('plots', 120),\n",
       " ('save_array', 120),\n",
       " ('shared', 120),\n",
       " ('split_at', 120),\n",
       " ('to_bw', 120),\n",
       " ('to_categorical', 120),\n",
       " ('to_plot', 120),\n",
       " ('vgg_ft', 120),\n",
       " ('vgg_ft_bn', 120),\n",
       " ('vgg_preprocess', 120),\n",
       " ('wrap_config', 120),\n",
       " ('zoom', 120),\n",
       " ('path_to_data', 105),\n",
       " ('Vgg16', 104),\n",
       " ('Vgg16BN', 104),\n",
       " ('absolute_import', 72),\n",
       " ('choice', 72),\n",
       " ('division', 72),\n",
       " ('normal', 72),\n",
       " ('permutation', 72),\n",
       " ('print_function', 72),\n",
       " ('randn', 72),\n",
       " ('uniform', 72),\n",
       " ('vgg', 72),\n",
       " ('batches', 64),\n",
       " ('bn_model', 64),\n",
       " ('conv_model', 64),\n",
       " ('gen_t', 64),\n",
       " ('l', 64),\n",
       " ('model', 64),\n",
       " ('test_batches', 64),\n",
       " ('val_batches', 64),\n",
       " ('Image', 56),\n",
       " ('K', 56),\n",
       " ('T', 56),\n",
       " ('activations', 56),\n",
       " ('constraints', 56),\n",
       " ('cuda', 56),\n",
       " ('image', 56),\n",
       " ('initializations', 56),\n",
       " ('misc', 56),\n",
       " ('ndimage', 56),\n",
       " ('nnet', 56),\n",
       " ('np', 56),\n",
       " ('np_utils', 56),\n",
       " ('pd', 56),\n",
       " ('plt', 56),\n",
       " ('pool', 56),\n",
       " ('regularizers', 56),\n",
       " ('sequence', 56),\n",
       " ('path', 48),\n",
       " ('batch_size', 24),\n",
       " ('i', 24),\n",
       " ('last_conv_idx', 24),\n",
       " ('p', 24),\n",
       " ('newaxis', 16)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MEMORY USAGE\n",
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HAD TO FREE UP MEMORY\n",
    "del conv_test_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/ubuntu/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-stretch-sid-x86_64-2.7.12-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16564 samples, validate on 5786 samples\n",
      "Epoch 1/1\n",
      "16564/16564 [==============================] - 12s - loss: 1.5518 - acc: 0.5754 - val_loss: 0.6196 - val_acc: 0.8078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd81e389f90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=1, \n",
    "            validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16564 samples, validate on 5786 samples\n",
      "Epoch 1/1\n",
      "16564/16564 [==============================] - 12s - loss: 0.2913 - acc: 0.9133 - val_loss: 0.5981 - val_acc: 0.7933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd81e3ae650>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=1, \n",
    "            validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path_to_data + \"/models/conv_bn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next up - precomputed conv features of augmented data followed by batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the plan is to get augmented training data, get conv output on them, concatenate that with our previous conv_features and\n",
    "# use it to train a slightly different batchnormed+dropout dense model. We will also use a multiplier on the amount of data\n",
    "# we predict on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16564 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# get augmented data\n",
    "# AGAIN, WIimage.ImageDataGeneratorrrrrr NEED TO NOT SHUFFLE DATA\n",
    "augment_d = image.ImageDataGenerator(width_shift_range=0.01, height_shift_range=0.05, \n",
    "                                    channel_shift_range=20, shear_range=0.1, rotation_range=15)\n",
    "da_batches = get_batches(path_to_data + \"/train/\", augment_d, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HERE WE USE THE TRICK OF MULTIPLYING DATA\n",
    "da_conv_feat = conv_model.predict_generator(da_batches, da_batches.nb_sample * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the array\n",
    "save_array(path_to_data + \"/results/da_conv_feat2.dat\", da_conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-dfed0d728be7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mda_conv_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_data\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/results/da_conv_feat2.dat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mutils.pyc\u001b[0m in \u001b[0;36mload_array\u001b[0;34m(fname)\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray.__getitem__ (bcolz/carray_ext.c:25668)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load the array\n",
    "da_conv_feat = load_array(path_to_data + \"/results/da_conv_feat2.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate the augmented conv_feat with the unaugmented ones\n",
    "da_conv_feat = np.concatenate([conv_feat, da_conv_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we also need to get labels for the TRIPLE conv feat\n",
    "da_labels = np.concatenate([trn_labels] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit the batchnorm dense model on top\n",
    "def get_bn_da_layers(p):\n",
    "    return [\n",
    "            MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "            Flatten(),\n",
    "            Dropout(p),\n",
    "            Dense(256, activation=\"relu\"),\n",
    "            BatchNormalization(),\n",
    "            Dropout(p),\n",
    "            Dense(256, activation=\"relu\"),\n",
    "            BatchNormalization(),\n",
    "            Dropout(p),\n",
    "            Dense(10, activation=\"softmax\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_da_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49692 samples, validate on 5786 samples\n",
      "Epoch 1/1\n",
      "49692/49692 [==============================] - 33s - loss: 1.9847 - acc: 0.4000 - val_loss: 0.7019 - val_acc: 0.8076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ea9b1fe90>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model, using the augmented data conv_features\n",
    "bn_model.fit(da_conv_feat, da_labels, batch_size=batch_size, nb_epoch=1, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49692 samples, validate on 5786 samples\n",
      "Epoch 1/4\n",
      "49692/49692 [==============================] - 33s - loss: 0.8019 - acc: 0.7277 - val_loss: 0.4961 - val_acc: 0.8391\n",
      "Epoch 2/4\n",
      "49692/49692 [==============================] - 33s - loss: 0.5961 - acc: 0.8033 - val_loss: 0.4377 - val_acc: 0.8495\n",
      "Epoch 3/4\n",
      "49692/49692 [==============================] - 33s - loss: 0.4973 - acc: 0.8386 - val_loss: 0.4305 - val_acc: 0.8612\n",
      "Epoch 4/4\n",
      "49692/49692 [==============================] - 33s - loss: 0.4475 - acc: 0.8562 - val_loss: 0.4247 - val_acc: 0.8515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2eab98c310>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigger lr\n",
    "bn_model.optimizer.lr = 0.01\n",
    "\n",
    "# fit for a couple more epochs\n",
    "bn_model.fit(da_conv_feat, da_labels, batch_size=batch_size, nb_epoch=4,\n",
    "            validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save weights\n",
    "bn_model.save_weights(path_to_data + \"/models/da_conv_bn_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49692 samples, validate on 5786 samples\n",
      "Epoch 1/1\n",
      "49692/49692 [==============================] - 32s - loss: 0.3708 - acc: 0.8811 - val_loss: 0.4061 - val_acc: 0.8648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ea9b1ff50>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smaller lr\n",
    "bn_model.optimizer.lr = 0.0001\n",
    "\n",
    "# fit for a couple more epochs\n",
    "bn_model.fit(da_conv_feat, da_labels, batch_size=batch_size, nb_epoch=1,\n",
    "            validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save weights\n",
    "bn_model.save_weights(path_to_data + \"/models/da_conv_bn_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('da_conv_feat', 19946766480),\n",
       " ('conv_feat', 6648922256),\n",
       " ('conv_val_feat', 2322546832),\n",
       " ('da_labels', 3975472),\n",
       " ('trn_labels', 1325232),\n",
       " ('test_filenames', 651360),\n",
       " ('val_labels', 462992),\n",
       " ('filenames', 140592),\n",
       " ('trn_classes', 66352),\n",
       " ('val_filenames', 48472),\n",
       " ('val_classes', 23240),\n",
       " ('Activation', 904),\n",
       " ('Adam', 904),\n",
       " ('AtrousConv1D', 904),\n",
       " ('AtrousConv2D', 904),\n",
       " ('AtrousConvolution1D', 904),\n",
       " ('AtrousConvolution2D', 904),\n",
       " ('AveragePooling1D', 904),\n",
       " ('AveragePooling2D', 904),\n",
       " ('AveragePooling3D', 904),\n",
       " ('BatchNormalization', 904),\n",
       " ('Bidirectional', 904),\n",
       " ('Conv1D', 904),\n",
       " ('Conv2D', 904),\n",
       " ('Conv3D', 904),\n",
       " ('Convolution1D', 904),\n",
       " ('Convolution2D', 904),\n",
       " ('Convolution3D', 904),\n",
       " ('Cropping1D', 904),\n",
       " ('Cropping2D', 904),\n",
       " ('Cropping3D', 904),\n",
       " ('Deconv2D', 904),\n",
       " ('Deconvolution2D', 904),\n",
       " ('Dense', 904),\n",
       " ('Dropout', 904),\n",
       " ('Embedding', 904),\n",
       " ('FileLink', 904),\n",
       " ('Flatten', 904),\n",
       " ('GRU', 904),\n",
       " ('GlobalAveragePooling2D', 904),\n",
       " ('InputSpec', 904),\n",
       " ('LSTM', 904),\n",
       " ('Lambda', 904),\n",
       " ('Layer', 904),\n",
       " ('MaxPooling1D', 904),\n",
       " ('MaxPooling2D', 904),\n",
       " ('MaxPooling3D', 904),\n",
       " ('MixIterator', 904),\n",
       " ('Model', 904),\n",
       " ('OneHotEncoder', 904),\n",
       " ('OrderedDict', 904),\n",
       " ('RMSprop', 904),\n",
       " ('Reshape', 904),\n",
       " ('SGD', 904),\n",
       " ('SeparableConv2D', 904),\n",
       " ('SeparableConvolution2D', 904),\n",
       " ('Sequential', 904),\n",
       " ('SimpleRNN', 904),\n",
       " ('TSNE', 904),\n",
       " ('TimeDistributed', 904),\n",
       " ('Tokenizer', 904),\n",
       " ('UpSampling1D', 904),\n",
       " ('UpSampling2D', 904),\n",
       " ('UpSampling3D', 904),\n",
       " ('ZeroPadding1D', 904),\n",
       " ('ZeroPadding2D', 904),\n",
       " ('ZeroPadding3D', 904),\n",
       " ('attrgetter', 872),\n",
       " ('chain', 872),\n",
       " ('itemgetter', 872),\n",
       " ('methodcaller', 872),\n",
       " ('conv_layers', 320),\n",
       " ('vgg_mean', 128),\n",
       " ('Input', 120),\n",
       " ('activity_l1', 120),\n",
       " ('activity_l2', 120),\n",
       " ('adjust_dropout', 120),\n",
       " ('categorical_accuracy', 120),\n",
       " ('categorical_crossentropy', 120),\n",
       " ('ceil', 120),\n",
       " ('confusion_matrix', 120),\n",
       " ('conv2d', 120),\n",
       " ('conv_input_length', 120),\n",
       " ('conv_output_length', 120),\n",
       " ('copy_layer', 120),\n",
       " ('copy_layers', 120),\n",
       " ('copy_model', 120),\n",
       " ('copy_weights', 120),\n",
       " ('do_clip', 120),\n",
       " ('floor', 120),\n",
       " ('get_batches', 120),\n",
       " ('get_bn_da_layers', 120),\n",
       " ('get_bn_layers', 120),\n",
       " ('get_classes', 120),\n",
       " ('get_data', 120),\n",
       " ('get_file', 120),\n",
       " ('gray', 120),\n",
       " ('imread', 120),\n",
       " ('insert_layer', 120),\n",
       " ('l1', 120),\n",
       " ('l2', 120),\n",
       " ('layer_from_config', 120),\n",
       " ('load_array', 120),\n",
       " ('merge', 120),\n",
       " ('mk_size', 120),\n",
       " ('mk_square', 120),\n",
       " ('onehot', 120),\n",
       " ('plot', 120),\n",
       " ('plot_confusion_matrix', 120),\n",
       " ('plots', 120),\n",
       " ('save_array', 120),\n",
       " ('shared', 120),\n",
       " ('split_at', 120),\n",
       " ('to_bw', 120),\n",
       " ('to_categorical', 120),\n",
       " ('to_plot', 120),\n",
       " ('vgg_ft', 120),\n",
       " ('vgg_ft_bn', 120),\n",
       " ('vgg_preprocess', 120),\n",
       " ('wrap_config', 120),\n",
       " ('zoom', 120),\n",
       " ('path_to_data', 105),\n",
       " ('Vgg16', 104),\n",
       " ('Vgg16BN', 104),\n",
       " ('absolute_import', 72),\n",
       " ('choice', 72),\n",
       " ('division', 72),\n",
       " ('normal', 72),\n",
       " ('permutation', 72),\n",
       " ('print_function', 72),\n",
       " ('randn', 72),\n",
       " ('uniform', 72),\n",
       " ('vgg', 72),\n",
       " ('augment_d', 64),\n",
       " ('batches', 64),\n",
       " ('bn_model', 64),\n",
       " ('conv_model', 64),\n",
       " ('da_batches', 64),\n",
       " ('l', 64),\n",
       " ('model', 64),\n",
       " ('test_batches', 64),\n",
       " ('val_batches', 64),\n",
       " ('Image', 56),\n",
       " ('K', 56),\n",
       " ('T', 56),\n",
       " ('activations', 56),\n",
       " ('constraints', 56),\n",
       " ('cuda', 56),\n",
       " ('image', 56),\n",
       " ('initializations', 56),\n",
       " ('misc', 56),\n",
       " ('ndimage', 56),\n",
       " ('nnet', 56),\n",
       " ('np', 56),\n",
       " ('np_utils', 56),\n",
       " ('pd', 56),\n",
       " ('plt', 56),\n",
       " ('pool', 56),\n",
       " ('regularizers', 56),\n",
       " ('sequence', 56),\n",
       " ('path', 48),\n",
       " ('x', 38),\n",
       " ('batch_size', 24),\n",
       " ('i', 24),\n",
       " ('last_conv_idx', 24),\n",
       " ('p', 24),\n",
       " ('newaxis', 16)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MEMORY USAGE\n",
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudolabeling\n",
    "Pseudolabelling is about semi-supervised training - it's about using unlabeled data in training, by assuming that the labels our model predicts for them are good. In practice we'll use our validation set, which is weird.\n",
    "\n",
    "Distilling knowledge is like a vanilla version of ensembling (using many good models and averaging their results) - it manages to do that without creating many models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we could use the test set instead of the val set (as it's truly unlabeled)\n",
    "val_pseudo = bn_model.predict(conv_val_feat, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb_labels = np.concatenate([da_labels, val_pseudo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comb_feat = np.concatenate([da_conv_feat, conv_val_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights(path_to_data + \"/models/da_conv_bn_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55478 samples, validate on 5786 samples\n",
      "Epoch 1/1\n",
      "55478/55478 [==============================] - 37s - loss: 0.4711 - acc: 0.8559 - val_loss: 0.3574 - val_acc: 0.8802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ea9513d90>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(comb_feat, comb_labels, batch_size=batch_size, nb_epoch=1,\n",
    "            validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55478 samples, validate on 5786 samples\n",
      "Epoch 1/4\n",
      "55478/55478 [==============================] - 37s - loss: 0.4086 - acc: 0.8791 - val_loss: 0.3878 - val_acc: 0.8830\n",
      "Epoch 2/4\n",
      "55478/55478 [==============================] - 36s - loss: 0.3859 - acc: 0.8873 - val_loss: 0.3655 - val_acc: 0.8839\n",
      "Epoch 3/4\n",
      "55478/55478 [==============================] - 37s - loss: 0.3670 - acc: 0.8939 - val_loss: 0.3944 - val_acc: 0.8764\n",
      "Epoch 4/4\n",
      "55478/55478 [==============================] - 36s - loss: 0.3540 - acc: 0.8983 - val_loss: 0.3881 - val_acc: 0.8859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ec0965050>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(comb_feat, comb_labels, batch_size=batch_size, nb_epoch=2,\n",
    "            validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# smaller lr at the end\n",
    "bn_model.optimizer.lr=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55478 samples, validate on 5786 samples\n",
      "Epoch 1/2\n",
      "55478/55478 [==============================] - 37s - loss: 0.4149 - acc: 0.8782 - val_loss: 0.3646 - val_acc: 0.8901\n",
      "Epoch 2/2\n",
      "55478/55478 [==============================] - 37s - loss: 0.3867 - acc: 0.8870 - val_loss: 0.3409 - val_acc: 0.8887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ebbf50d10>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(comb_feat, comb_labels, batch_size=batch_size, nb_epoch=2,\n",
    "            validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# smaller lr at the end\n",
    "bn_model.optimizer.lr=0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55478 samples, validate on 5786 samples\n",
      "Epoch 1/1\n",
      "55478/55478 [==============================] - 37s - loss: 0.3602 - acc: 0.8963 - val_loss: 0.3730 - val_acc: 0.8897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ebbf50d50>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(comb_feat, comb_labels, batch_size=batch_size, nb_epoch=1,\n",
    "            validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we could use THE ENTIRE TRAINING SET and train on that one in this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save weights\n",
    "bn_model.save_weights(path_to_data + \"/models/da_conv_bn_3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('comb_feat', 22269313168),\n",
       " ('da_conv_feat', 19946766480),\n",
       " ('conv_feat', 6648922256),\n",
       " ('conv_val_feat', 2322546832),\n",
       " ('comb_labels', 4438352),\n",
       " ('da_labels', 3975472),\n",
       " ('trn_labels', 1325232),\n",
       " ('test_filenames', 651360),\n",
       " ('val_labels', 462992),\n",
       " ('val_pseudo', 231552),\n",
       " ('filenames', 140592),\n",
       " ('trn_classes', 66352),\n",
       " ('val_filenames', 48472),\n",
       " ('val_classes', 23240),\n",
       " ('Activation', 904),\n",
       " ('Adam', 904),\n",
       " ('AtrousConv1D', 904),\n",
       " ('AtrousConv2D', 904),\n",
       " ('AtrousConvolution1D', 904),\n",
       " ('AtrousConvolution2D', 904),\n",
       " ('AveragePooling1D', 904),\n",
       " ('AveragePooling2D', 904),\n",
       " ('AveragePooling3D', 904),\n",
       " ('BatchNormalization', 904),\n",
       " ('Bidirectional', 904),\n",
       " ('Conv1D', 904),\n",
       " ('Conv2D', 904),\n",
       " ('Conv3D', 904),\n",
       " ('Convolution1D', 904),\n",
       " ('Convolution2D', 904),\n",
       " ('Convolution3D', 904),\n",
       " ('Cropping1D', 904),\n",
       " ('Cropping2D', 904),\n",
       " ('Cropping3D', 904),\n",
       " ('Deconv2D', 904),\n",
       " ('Deconvolution2D', 904),\n",
       " ('Dense', 904),\n",
       " ('Dropout', 904),\n",
       " ('Embedding', 904),\n",
       " ('FileLink', 904),\n",
       " ('Flatten', 904),\n",
       " ('GRU', 904),\n",
       " ('GlobalAveragePooling2D', 904),\n",
       " ('InputSpec', 904),\n",
       " ('LSTM', 904),\n",
       " ('Lambda', 904),\n",
       " ('Layer', 904),\n",
       " ('MaxPooling1D', 904),\n",
       " ('MaxPooling2D', 904),\n",
       " ('MaxPooling3D', 904),\n",
       " ('MixIterator', 904),\n",
       " ('Model', 904),\n",
       " ('OneHotEncoder', 904),\n",
       " ('OrderedDict', 904),\n",
       " ('RMSprop', 904),\n",
       " ('Reshape', 904),\n",
       " ('SGD', 904),\n",
       " ('SeparableConv2D', 904),\n",
       " ('SeparableConvolution2D', 904),\n",
       " ('Sequential', 904),\n",
       " ('SimpleRNN', 904),\n",
       " ('TSNE', 904),\n",
       " ('TimeDistributed', 904),\n",
       " ('Tokenizer', 904),\n",
       " ('UpSampling1D', 904),\n",
       " ('UpSampling2D', 904),\n",
       " ('UpSampling3D', 904),\n",
       " ('ZeroPadding1D', 904),\n",
       " ('ZeroPadding2D', 904),\n",
       " ('ZeroPadding3D', 904),\n",
       " ('attrgetter', 872),\n",
       " ('chain', 872),\n",
       " ('itemgetter', 872),\n",
       " ('methodcaller', 872),\n",
       " ('conv_layers', 320),\n",
       " ('vgg_mean', 128),\n",
       " ('Input', 120),\n",
       " ('activity_l1', 120),\n",
       " ('activity_l2', 120),\n",
       " ('adjust_dropout', 120),\n",
       " ('categorical_accuracy', 120),\n",
       " ('categorical_crossentropy', 120),\n",
       " ('ceil', 120),\n",
       " ('confusion_matrix', 120),\n",
       " ('conv2d', 120),\n",
       " ('conv_input_length', 120),\n",
       " ('conv_output_length', 120),\n",
       " ('copy_layer', 120),\n",
       " ('copy_layers', 120),\n",
       " ('copy_model', 120),\n",
       " ('copy_weights', 120),\n",
       " ('do_clip', 120),\n",
       " ('floor', 120),\n",
       " ('get_batches', 120),\n",
       " ('get_bn_da_layers', 120),\n",
       " ('get_bn_layers', 120),\n",
       " ('get_classes', 120),\n",
       " ('get_data', 120),\n",
       " ('get_file', 120),\n",
       " ('gray', 120),\n",
       " ('imread', 120),\n",
       " ('insert_layer', 120),\n",
       " ('l1', 120),\n",
       " ('l2', 120),\n",
       " ('layer_from_config', 120),\n",
       " ('load_array', 120),\n",
       " ('merge', 120),\n",
       " ('mk_size', 120),\n",
       " ('mk_square', 120),\n",
       " ('onehot', 120),\n",
       " ('plot', 120),\n",
       " ('plot_confusion_matrix', 120),\n",
       " ('plots', 120),\n",
       " ('save_array', 120),\n",
       " ('shared', 120),\n",
       " ('split_at', 120),\n",
       " ('to_bw', 120),\n",
       " ('to_categorical', 120),\n",
       " ('to_plot', 120),\n",
       " ('vgg_ft', 120),\n",
       " ('vgg_ft_bn', 120),\n",
       " ('vgg_preprocess', 120),\n",
       " ('wrap_config', 120),\n",
       " ('zoom', 120),\n",
       " ('path_to_data', 105),\n",
       " ('Vgg16', 104),\n",
       " ('Vgg16BN', 104),\n",
       " ('absolute_import', 72),\n",
       " ('choice', 72),\n",
       " ('division', 72),\n",
       " ('normal', 72),\n",
       " ('permutation', 72),\n",
       " ('print_function', 72),\n",
       " ('randn', 72),\n",
       " ('uniform', 72),\n",
       " ('vgg', 72),\n",
       " ('augment_d', 64),\n",
       " ('batches', 64),\n",
       " ('bn_model', 64),\n",
       " ('conv_model', 64),\n",
       " ('da_batches', 64),\n",
       " ('l', 64),\n",
       " ('model', 64),\n",
       " ('test_batches', 64),\n",
       " ('val_batches', 64),\n",
       " ('Image', 56),\n",
       " ('K', 56),\n",
       " ('T', 56),\n",
       " ('activations', 56),\n",
       " ('constraints', 56),\n",
       " ('cuda', 56),\n",
       " ('image', 56),\n",
       " ('initializations', 56),\n",
       " ('misc', 56),\n",
       " ('ndimage', 56),\n",
       " ('nnet', 56),\n",
       " ('np', 56),\n",
       " ('np_utils', 56),\n",
       " ('pd', 56),\n",
       " ('plt', 56),\n",
       " ('pool', 56),\n",
       " ('regularizers', 56),\n",
       " ('sequence', 56),\n",
       " ('path', 48),\n",
       " ('x', 38),\n",
       " ('batch_size', 24),\n",
       " ('i', 24),\n",
       " ('last_conv_idx', 24),\n",
       " ('p', 24),\n",
       " ('newaxis', 16)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MEMORY USAGE\n",
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEED TO FREE UP MEMORY BEFORE operating on the test set\n",
    "del comb_feat\n",
    "del da_conv_feat\n",
    "del conv_feat\n",
    "del da_labels\n",
    "del trn_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# why divide by 9?\n",
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/9, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we need to use the model to predict val_preds, I think\n",
    "val_preds = bn_model.predict(conv_val_feat, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.44426681360920695)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not sure if cross entropy is good when small or big\n",
    "keras.metrics.categorical_crossentropy(val_labels, do_clip(val_preds, 0.89)).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_test_feat = load_array(path_to_data +'results/conv_test_feat.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = bn_model.predict(conv_test_feat, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = do_clip(preds,0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_name = path_to_data +'results/subm_3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n"
     ]
    }
   ],
   "source": [
    "# this is weird...\n",
    "classes = sorted(batches.class_indices, key=batches.class_indices.get)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_81601.jpg</td>\n",
       "      <td>0.071730</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.008983</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.022735</td>\n",
       "      <td>0.035755</td>\n",
       "      <td>0.135804</td>\n",
       "      <td>0.716470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_14887.jpg</td>\n",
       "      <td>0.603387</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.027201</td>\n",
       "      <td>0.345809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_62885.jpg</td>\n",
       "      <td>0.036221</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.053953</td>\n",
       "      <td>0.881569</td>\n",
       "      <td>0.006774</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.007683</td>\n",
       "      <td>0.008447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_45125.jpg</td>\n",
       "      <td>0.012130</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.035124</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.019442</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.621067</td>\n",
       "      <td>0.025236</td>\n",
       "      <td>0.251576</td>\n",
       "      <td>0.029713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_22633.jpg</td>\n",
       "      <td>0.059357</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.008725</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.006533</td>\n",
       "      <td>0.247365</td>\n",
       "      <td>0.638516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             img        c0        c1        c2        c3        c4        c5  \\\n",
       "0  img_81601.jpg  0.071730  0.005556  0.008983  0.005556  0.005556  0.005556   \n",
       "1  img_14887.jpg  0.603387  0.009996  0.005556  0.005556  0.005556  0.006691   \n",
       "2  img_62885.jpg  0.036221  0.005556  0.005556  0.053953  0.881569  0.006774   \n",
       "3  img_45125.jpg  0.012130  0.005556  0.035124  0.005556  0.019442  0.005556   \n",
       "4  img_22633.jpg  0.059357  0.031130  0.005556  0.005556  0.005556  0.008725   \n",
       "\n",
       "         c6        c7        c8        c9  \n",
       "0  0.022735  0.035755  0.135804  0.716470  \n",
       "1  0.005556  0.005556  0.027201  0.345809  \n",
       "2  0.005556  0.005556  0.007683  0.008447  \n",
       "3  0.621067  0.025236  0.251576  0.029713  \n",
       "4  0.005556  0.006533  0.247365  0.638516  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "submission.insert(0, 'img', [a[8:] for a in test_filenames])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv(subm_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/home/ubuntu/courses/deeplearning1/nbs/kaggle_data/state-farm-redux/results/subm_3.csv' target='_blank'>/home/ubuntu/courses/deeplearning1/nbs/kaggle_data/state-farm-redux/results/subm_3.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/courses/deeplearning1/nbs/kaggle_data/state-farm-redux/results/subm_3.csv"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full stop :)\n"
     ]
    }
   ],
   "source": [
    "print(\"Full stop :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
